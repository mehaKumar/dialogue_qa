{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Model:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "    \n",
    "    def answer(self, text, questions):\n",
    "        answerss = []\n",
    "        for question in questions:\n",
    "            inputs = self.tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "            input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "            text_tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
    "            answer_start_scores, answer_end_scores = self.model(**inputs, return_dict=False)\n",
    "\n",
    "            answer_start = torch.argmax(\n",
    "                answer_start_scores\n",
    "            )  # Get the most likely beginning of answer with the argmax of the score\n",
    "            answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "            answer = self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {answer}\")\n",
    "            print(f\"Score: {torch.max(answer_start_scores)}\")\n",
    "            \n",
    "            if torch.max(answer_start_scores) < 0:\n",
    "                answer = \" \"\n",
    "            answerss.append(answer)\n",
    "        return answerss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/'\n",
    "file = 'event_815871.txt'\n",
    "\n",
    "questions = [\"Who is the suspicious person?\",\n",
    "             \"Where is the suspicious person?\",\n",
    "             \"When did the suspicous activity take place?\"]\n",
    "\n",
    "qa = QA_Model()\n",
    "\n",
    "answers = [[\" \"],[\" \"],[\" \"]]\n",
    "f = open(folder + file)\n",
    "text = f.readlines()\n",
    "\n",
    "for i in range(len(text)):\n",
    "    print(str(i) + \" \" + text[i])\n",
    "    \n",
    "for i in range(len(text)):\n",
    "    print(f\"Up to line {i}\")\n",
    "    section = \" \".join(text[:i+1])\n",
    "    answers_i = qa.answer(section, questions)\n",
    "    for j in range(len(answers_i)):\n",
    "        if answers_i[j] not in answers[j]:\n",
    "            answers[j].append(answers_i[j])\n",
    "print(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
